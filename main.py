import os
import json
import mimetypes

import pandas as pd
import fitz  # PyMuPDF
import docx
import spacy

from pathlib import Path


# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ spaCy ===
try:
    nlp = spacy.load("en_core_web_sm")
except:
    import subprocess
    subprocess.run(["python", "-m", "spacy", "download", "en_core_web_sm"])
    nlp = spacy.load("en_core_web_sm")


# === –°—á–∏—Ç—ã–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–æ–≤ ===
def read_pdf(path):
    try:
        text = ""
        with fitz.open(path) as doc:
            for page in doc:
                text += page.get_text()  # type: ignore
        return text.strip()
    except Exception as e:
        raise Exception(f"Error reading PDF file: {str(e)}")


def read_docx(path):
    try:
        doc = docx.Document(path)
        return "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
    except Exception as e:
        raise Exception(f"Error reading DOCX file: {str(e)}")


def read_txt(path):
    try:
        # Try UTF-8 first, then fallback to other encodings
        encodings = ['utf-8', 'cp1252', 'latin-1', 'iso-8859-1']
        for encoding in encodings:
            try:
                with open(path, "r", encoding=encoding) as f:
                    return f.read()
            except UnicodeDecodeError:
                continue
        # If all encodings fail, try with error handling
        with open(path, "r", encoding='utf-8', errors='ignore') as f:
            return f.read()
    except Exception as e:
        raise Exception(f"Error reading TXT file: {str(e)}")


def read_xlsx(path):
    try:
        df = pd.read_excel(path)
        return df
    except Exception as e:
        raise Exception(f"Error reading XLSX file: {str(e)}")


# === –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ ===
def detect_doc_type(text):
    text_lower = text.lower()
    if "curriculum vitae" in text_lower or "resume" in text_lower or "–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ" in text_lower:
        return "CV"
    elif "invoice" in text_lower or "—Å—á–µ—Ç" in text_lower or "total" in text_lower:
        return "Invoice"
    elif "latitude" in text_lower or "longitude" in text_lower or "city" in text_lower:
        return "Analytics"
    return "Unknown"


# === –í—ã–¥–µ–ª–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π ===
def extract_entities(text):
    doc = nlp(text)
    results = []
    for ent in doc.ents:
        results.append({
            "text": ent.text,
            "label": ent.label_
        })
    return results


# === –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ ===
def process_file(path):
    extension = Path(path).suffix.lower()

    if extension == ".pdf":
        content = read_pdf(path)
    elif extension == ".docx":
        content = read_docx(path)
    elif extension == ".txt":
        content = read_txt(path)
    elif extension == ".xlsx":
        content = read_xlsx(path)
    else:
        raise ValueError("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞.")

    return content


# === –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ (Excel) ===
def summarize_analytics(df):
    return f"–¢–∞–±–ª–∏—Ü–∞ —Å {df.shape[0]} —Å—Ç—Ä–æ–∫–∞–º–∏ –∏ {df.shape[1]} —Å—Ç–æ–ª–±—Ü–∞–º–∏."


# === –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É ===
def convert_for_json(obj):
    if isinstance(obj, dict):
        return {k: convert_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_for_json(i) for i in obj]
    elif isinstance(obj, (pd.Timestamp, pd.Series, pd.DataFrame)):
        return str(obj)
    elif hasattr(obj, 'isoformat'):  # datetime
        return obj.isoformat()
    elif isinstance(obj, str):
        # Ensure string is properly encoded
        try:
            return obj.encode('utf-8').decode('utf-8')
        except:
            return obj.encode('ascii', errors='ignore').decode('ascii')
    return obj


# === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ===
def save_to_json(filename: str, file_type: str, full_text, entities: list, summary: str):
    result = {
        "filename": filename,
        "type": file_type,
        "summary": summary,
        "entities": entities,
        "full_text": full_text
    }

    result = convert_for_json(result)

    try:
        with open("results.json", "w", encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=4)
    except Exception as e:
        # Fallback: try with ASCII encoding
        with open("results.json", "w", encoding='ascii', errors='ignore') as f:
            json.dump(result, f, ensure_ascii=True, indent=4)


# === –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ===
def main():
    try:
        # Set up proper encoding for input/output
        import sys
        import locale
        
        # Set environment variable for UTF-8 encoding
        import os
        os.environ['PYTHONIOENCODING'] = 'utf-8'
        
        path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (PDF, DOCX, TXT, XLSX): ").strip()

        if not os.path.exists(path):
            print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            return

        print("\n‚úÖ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—á–∏—Ç–∞–Ω–æ. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞...\n")

        content = process_file(path)

        if isinstance(content, pd.DataFrame):
            text = content.to_string(index=False)
            file_type = detect_doc_type(" ".join(content.columns.tolist()))
            summary = summarize_analytics(content)
            entities = []
        else:
            text = content
            file_type = detect_doc_type(text)
            summary = f"–¢–µ–∫—Å—Ç –∏–∑ {file_type} —Ñ–∞–π–ª–∞." if file_type != "Unknown" else "–û–±—â–∏–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç."
            entities = extract_entities(text)

        print(f"üìÇ –¢–∏–ø —Ñ–∞–π–ª–∞: {file_type}\n")
        print("üìÑ –§—Ä–∞–≥–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ:\n")
        print(text[:1500] + "...\n" if len(text) > 1500 else text + "\n")

        if entities:
            print("üîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏:")
            for e in entities:
                # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: —É–±—Ä–∞–ª –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ
                print(f"{e['label']}: {e['text']}")

        save_to_json(path, file_type, content, entities, summary)
        print("\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ results.json")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
        import traceback
        print(f"Traceback: {traceback.format_exc()}")
        return


if __name__ == "__main__":
    main()